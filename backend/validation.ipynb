{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74ccfbf0-bcda-4962-bf77-21787c580036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.3.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 1.3.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator FunctionTransformer from version 1.3.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator ColumnTransformer from version 1.3.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DummyClassifier from version 1.3.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 1.3.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.3.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading GradientBoosting: node array from the pickle has an incompatible dtype:\n",
      "- expected: [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]\n",
      "- got     : {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object Thread can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 175\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(result, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Run in Jupyter Notebook\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_validation()\n",
      "Cell \u001b[1;32mIn[17], line 171\u001b[0m, in \u001b[0;36mrun_validation\u001b[1;34m()\u001b[0m\n\u001b[0;32m    145\u001b[0m bill_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoice_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX33\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoice_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-02-07\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayment_terms\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayment due in 15 days\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m }\n\u001b[0;32m    170\u001b[0m service \u001b[38;5;241m=\u001b[39m ExpenseValidationService(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-proj-076VLCR1__D-xNaqmx_63Y-U3GwKXGisWE3kbpoNDcsyuzAD-Jwd6d64K2llqAZO6SQY1BLzWKT3BlbkFJkgOjf8yVmvfQBDu8Tj7SwP2WNRfK3uWA5JsGWsjfW16nFJJ_rz150UvpVlBQ-IhPexa8gY3cAA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masst_EpFa1gBPouBslsTcGOsLBEGE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 171\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m service\u001b[38;5;241m.\u001b[39mvalidate_expense_and_tax(expense_data, bill_data)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(result, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[1;32mIn[17], line 115\u001b[0m, in \u001b[0;36mExpenseValidationService.validate_expense_and_tax\u001b[1;34m(self, expense_data, bill_data)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_expense_and_tax\u001b[39m(\u001b[38;5;28mself\u001b[39m, expense_data: Dict[\u001b[38;5;28mstr\u001b[39m, Any], bill_data: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    114\u001b[0m     expense_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_expense(expense_data)\n\u001b[1;32m--> 115\u001b[0m     tax_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_tax_compliance(bill_data)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpense_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m: expense_validation,\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtax_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m: tax_validation,\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverall_status\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (expense_validation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverall_status\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m    120\u001b[0m                                     \u001b[38;5;129;01mand\u001b[39;00m tax_validation\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbill_valid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[17], line 65\u001b[0m, in \u001b[0;36mExpenseValidationService.validate_tax_compliance\u001b[1;34m(self, bill_data)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_tax_compliance\u001b[39m(\u001b[38;5;28mself\u001b[39m, bill_data: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m---> 65\u001b[0m     thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(bill_data))\n\u001b[0;32m     67\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mcreate(thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid, assistant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massistant_id)\n",
      "\u001b[1;31mTypeError\u001b[0m: object Thread can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import asyncio\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "from openai import OpenAI\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Function to install missing packages\n",
    "\n",
    "# Define the DateFeatureExtractor\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Custom transformer for extracting features from date columns. \"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['submission_date'] = pd.to_datetime(X['submission_date'])\n",
    "        X['expense_date'] = pd.to_datetime(X['expense_date'])\n",
    "        X['submission_delay'] = (X['submission_date'] - X['expense_date']).dt.days\n",
    "        X['day_of_week'] = X['expense_date'].dt.dayofweek\n",
    "        X['is_weekend'] = X['day_of_week'].isin([5, 6]).astype(int)\n",
    "        X['month'] = X['expense_date'].dt.month\n",
    "        X['quarter'] = X['expense_date'].dt.quarter\n",
    "        X['is_month_end'] = X['expense_date'].dt.is_month_end.astype(int)\n",
    "        return X.drop(['submission_date', 'expense_date'], axis=1)\n",
    "\n",
    "# Define the ExpenseValidationService\n",
    "class ExpenseValidationService:\n",
    "    def __init__(self, model_path: str, openai_key: str, assistant_id: str):\n",
    "        self.models = self._load_models(model_path)\n",
    "        self.client = OpenAI(api_key=openai_key)\n",
    "        self.assistant_id = assistant_id\n",
    "        self.date_extractor = DateFeatureExtractor()\n",
    "        self.allowed_budgets = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "        self.allowed_categories = {\n",
    "            \"Engineering\": [\"Travel\", \"Meals\", \"Supplies\"],\n",
    "            \"IT\": [\"Travel\", \"Supplies\"],\n",
    "            \"Finance\": [\"Travel\", \"Meals\"],\n",
    "            \"HR\": [\"Meals\"],\n",
    "            \"Operations\": [\"Travel\", \"Meals\", \"Supplies\"],\n",
    "            \"Sales\": [\"Travel\", \"Meals\"],\n",
    "            \"Marketing\": [\"Travel\", \"Meals\", \"Supplies\"]\n",
    "        }\n",
    "\n",
    "    def _load_models(self, model_path: str) -> Dict:\n",
    "        models = {}\n",
    "        for name in [ 'GradientBoosting', 'XGBoost', 'LogisticRegression']:\n",
    "            try:\n",
    "                models[name] = joblib.load(f\"{model_path}/{name}_model.joblib\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {name}: {e}\")\n",
    "        return models\n",
    "\n",
    "    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return self.date_extractor.transform(df)\n",
    "\n",
    "    async def validate_tax_compliance(self, bill_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        thread = await self.client.beta.threads.create()\n",
    "        await self.client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=str(bill_data))\n",
    "        run = await self.client.beta.threads.runs.create(thread_id=thread.id, assistant_id=self.assistant_id)\n",
    "        messages = await self.client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        response = messages.data[0].content[0].text.value\n",
    "        return eval(response)\n",
    "\n",
    "    def validate_expense(self, expense_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        df = pd.DataFrame([expense_data])\n",
    "        df_processed = self._preprocess_data(df)\n",
    "        predictions = {}\n",
    "        confidences = {}\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            try:\n",
    "                pred = model.predict(df_processed)[0]\n",
    "                prob = max(model.predict_proba(df_processed)[0]) * 100\n",
    "                predictions[name] = \"Violation\" if pred == 1 else \"Normal\"\n",
    "                confidences[name] = round(prob, 2)\n",
    "            except Exception as e:\n",
    "                predictions[name] = f\"Error: {str(e)}\"\n",
    "                confidences[name] = 0\n",
    "\n",
    "        compliance_flags = self._check_compliance(expense_data)\n",
    "        return {\n",
    "            \"ml_predictions\": {\"predictions\": predictions, \"confidences\": confidences},\n",
    "            \"rule_based_checks\": compliance_flags,\n",
    "            \"overall_status\": \"Violation\" if compliance_flags else \"Normal\"\n",
    "        }\n",
    "\n",
    "    def _check_compliance(self, expense: Dict[str, Any]) -> Dict[str, str]:\n",
    "        flags = {}\n",
    "        cat = expense.get('category')\n",
    "        dept = expense.get('department')\n",
    "        amt = expense.get('amount', 0)\n",
    "        notes = expense.get('notes', \"\").strip()\n",
    "\n",
    "        if cat in self.allowed_budgets and amt > self.allowed_budgets[cat]:\n",
    "            flags['Over Budget'] = f\"Amount {amt} exceeds budget {self.allowed_budgets[cat]} for {cat}\"\n",
    "\n",
    "        if dept in self.allowed_categories and cat not in self.allowed_categories[dept]:\n",
    "            flags['Unauthorized Category'] = f\"Category {cat} not allowed for {dept}\"\n",
    "\n",
    "        if cat in self.allowed_budgets and amt > self.allowed_budgets[cat] and not notes:\n",
    "            flags['Missing Justification'] = \"High amount claimed without justification\"\n",
    "\n",
    "        return flags\n",
    "\n",
    "    async def validate_expense_and_tax(self, expense_data: Dict[str, Any], bill_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        expense_validation = self.validate_expense(expense_data)\n",
    "        tax_validation = await self.validate_tax_compliance(bill_data)\n",
    "        return {\n",
    "            \"expense_validation\": expense_validation,\n",
    "            \"tax_validation\": tax_validation,\n",
    "            \"overall_status\": \"Valid\" if (expense_validation[\"overall_status\"] == \"Normal\" \n",
    "                                        and tax_validation.get(\"bill_valid\", False)) else \"Invalid\"\n",
    "        }\n",
    "\n",
    "# Define the main function\n",
    "async def run_validation():\n",
    "    expense_data = {\n",
    "        'expense_id': 201,\n",
    "        'employee_id': 1500,\n",
    "        'amount': 7500.00,\n",
    "        'receipt_quality': 0.65,\n",
    "        'ocr_confidence': 0.90,\n",
    "        'previous_violations': 1,\n",
    "        'department': 'Engineering',\n",
    "        'category': 'Travel',\n",
    "        'currency': 'INR',\n",
    "        'vendor_country': 'US',\n",
    "        'payment_method': 'Credit Card',\n",
    "        'expense_date': '2024-02-08',\n",
    "        'submission_date': '2024-02-08',\n",
    "        'requires_approval': 1,\n",
    "        'has_receipt': 1,\n",
    "        'manual_review_required': 0,\n",
    "        'notes': ''\n",
    "    }\n",
    "\n",
    "    bill_data = {\n",
    "        \"invoice_number\": \"X33\",\n",
    "        \"invoice_date\": \"2024-02-07\",\n",
    "        \"due_date\": \"2024-02-20\",\n",
    "        \"seller\": {\n",
    "            \"name\": \"Sleek Bill\",\n",
    "            \"address\": \"XYZ Building, New Delhi, India\",\n",
    "            \"gst_number\": \"27AABQA12S4A1Z5\",\n",
    "            \"contact\": \"+91 9876543210\"\n",
    "        },\n",
    "        \"buyer\": {\n",
    "            \"name\": \"AB Company\",\n",
    "            \"address\": \"ABC Tower, Mumbai, India\",\n",
    "            \"gst_number\": \"27AAAPA1234A1Z5\",\n",
    "            \"contact\": \"+91 9123456789\"\n",
    "        },\n",
    "        \"bill_items\": [\n",
    "            {\"description\": \"Service 1\", \"hsn_sac\": \"9983\", \"quantity\": 2, \"rate\": 5000, \"subtotal\": 10000, \"gst_rate\": 18, \"gst_amount\": 1800, \"total\": 11800}\n",
    "        ],\n",
    "        \"subtotal\": 10000,\n",
    "        \"gst_total\": 1800,\n",
    "        \"grand_total\": 11800,\n",
    "        \"payment_terms\": \"Payment due in 15 days\"\n",
    "    }\n",
    "\n",
    "    service = ExpenseValidationService(\"models/\", \"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\", \"asst_EpFa1gBPouBslsTcGOsLBEGE\")\n",
    "    result = await service.validate_expense_and_tax(expense_data, bill_data)\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "# Run in Jupyter Notebook\n",
    "await run_validation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a61a8331-30b3-444f-8ad7-2deba0016d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.2\n",
      "  Downloading scikit-learn-1.0.2.tar.gz (6.7 MB)\n",
      "     ---------------------------------------- 0.0/6.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.7 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/6.7 MB 1.1 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 0.5/6.7 MB 4.2 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.6/6.7 MB 3.7 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 1.2/6.7 MB 5.6 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 1.4/6.7 MB 6.3 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 2.0/6.7 MB 6.4 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.4/6.7 MB 7.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 2.8/6.7 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 3.3/6.7 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 3.4/6.7 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.6/6.7 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 3.8/6.7 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.4/6.7 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 5.1/6.7 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 5.2/6.7 MB 4.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 6.0/6.7 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 6.1/6.7 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.7/6.7 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.7/6.7 MB 5.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [1788 lines of output]\n",
      "  Partial import of sklearn during the build process.\n",
      "  setup.py:128: DeprecationWarning:\n",
      "  \n",
      "    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "    of the deprecation of `distutils` itself. It will be removed for\n",
      "    Python >= 3.12. For older Python versions it will remain present.\n",
      "    It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "    For more details, see:\n",
      "      https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \n",
      "  \n",
      "    from numpy.distutils.command.build_ext import build_ext  # noqa\n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\include -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\ATLMFC\\include -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um /Tctest_program.c /Foobjects\\test_program.obj\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\ATLMFC\\lib\\x64 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22621.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22621.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe\n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\include -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\ATLMFC\\include -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um /Tctest_program.c /Foobjects\\test_program.obj /openmp\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\ATLMFC\\lib\\x64 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22621.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22621.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe /openmp\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:27:5: Exception check on '_euclidean_dense_dense' will always require the GIL to be acquired. Declare '_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:59:5: Exception check on '_euclidean_sparse_dense' will always require the GIL to be acquired. Declare '_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:116:40: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:116:40: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:150:41: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:150:41: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:334:5: Exception check on '_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:569:5: Exception check on '_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:86:41: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:91:45: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:86:41: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:91:45: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:162:42: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:170:46: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:162:42: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:170:46: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:292:31: Exception check after calling '__pyx_fuse_0_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:292:31: Exception check after calling '__pyx_fuse_1_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:380:60: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:391:57: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:380:60: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:391:57: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:523:32: Exception check after calling '__pyx_fuse_0_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:523:32: Exception check after calling '__pyx_fuse_1_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:619:61: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:631:58: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:619:61: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:631:58: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:162:5: Exception check on '_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:356:5: Exception check on '_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:129:31: Exception check after calling '__pyx_fuse_0_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:129:31: Exception check after calling '__pyx_fuse_1_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:196:9: Exception check after calling '__pyx_fuse_0_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:196:9: Exception check after calling '__pyx_fuse_1_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:322:32: Exception check after calling '__pyx_fuse_0_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:322:32: Exception check after calling '__pyx_fuse_1_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:67:5: Exception check on 'update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:175:5: Exception check on 'update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'update_center_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:60:31: Exception check after calling '__pyx_fuse_0update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:60:31: Exception check after calling '__pyx_fuse_1update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:168:32: Exception check after calling '__pyx_fuse_0update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0update_center_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:168:32: Exception check after calling '__pyx_fuse_1update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1update_center_sparse' to allow an error code to be returned.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx:15:5: Exception check on 'init_bitset' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'init_bitset' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'init_bitset' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx:23:5: Exception check on 'set_bitset' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'set_bitset' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'set_bitset' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:10:28: No exception value declared for 'in_bitset' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:12:40: No exception value declared for 'in_bitset_memoryview' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:15:42: No exception value declared for 'in_bitset_2d_memoryview' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx:193:5: Exception check on '_compute_softmax' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_softmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_softmax' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx:173:28: Exception check after calling '_compute_softmax' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_softmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_softmax' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx:184:28: Exception check after calling '_compute_softmax' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_softmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_softmax' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:69:38: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:74:40: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:135:38: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:257:6: Exception check on '_build_histogram_naive' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_naive' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_naive' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:281:6: Exception check on '_subtract_histograms' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:305:6: Exception check on '_build_histogram' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:352:6: Exception check on '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:396:6: Exception check on '_build_histogram_root' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:449:6: Exception check on '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:161:60: Exception check after calling '_compute_histogram_brute_single_feature' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_histogram_brute_single_feature' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_histogram_brute_single_feature' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:193:48: Exception check after calling '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:197:37: Exception check after calling '_build_histogram_root' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:202:43: Exception check after calling '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:206:32: Exception check after calling '_build_histogram' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:249:32: Exception check after calling '_subtract_histograms' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          if n_used_bins <= 1:\n",
      "              free(cat_infos)\n",
      "              return\n",
      "  \n",
      "          qsort(cat_infos, n_used_bins, sizeof(categorical_info),\n",
      "                compare_cat_infos)\n",
      "                ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:920:14: Cannot assign type 'int (const void *, const void *) except? -1 nogil' to 'int (*)(const void *, const void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of 'compare_cat_infos'.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:46:5: Exception check on 'fmax' will always require the GIL to be acquired. Declare 'fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:52:5: Exception check on 'fsign' will always require the GIL to be acquired. Declare 'fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:61:5: Exception check on 'abs_max' will always require the GIL to be acquired. Declare 'abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:73:5: Exception check on 'max' will always require the GIL to be acquired. Declare 'max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:85:5: Exception check on 'diff_abs_max' will always require the GIL to be acquired. Declare 'diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:154:13: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:155:13: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:159:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:177:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:180:26: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:34: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:190:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:194:30: Exception check after calling '__pyx_fuse_0fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_0fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:206:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:207:21: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:213:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:218:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:221:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:231:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:235:38: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:154:13: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:155:13: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:159:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:177:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:180:26: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:34: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:190:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:194:30: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:206:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:207:21: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:213:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:218:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:221:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:231:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:235:38: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:353:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:396:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:396:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:437:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:439:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:442:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:445:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:454:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:456:54: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:353:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:396:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:396:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:437:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:439:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:442:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:445:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:454:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:456:54: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:563:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:563:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:568:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:585:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:590:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:592:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:601:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:612:37: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:563:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:563:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:568:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:585:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:590:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:592:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:601:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:612:37: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:694:35: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:697:13: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:701:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:705:25: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:720:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:732:29: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:742:34: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:746:26: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:749:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:750:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:750:21: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:763:29: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:767:37: Exception check after calling '__pyx_fuse_0diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:772:38: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:784:42: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:792:41: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:799:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:800:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:810:29: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:37: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:694:35: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:697:13: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:701:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:705:25: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:720:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:732:29: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:742:34: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:746:26: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:749:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:750:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:750:21: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:763:29: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:767:37: Exception check after calling '__pyx_fuse_1diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:772:38: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:784:42: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:792:41: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:799:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:800:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:810:29: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:37: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1198:5: Exception check on 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1245:5: Exception check on 'predict_sample32' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:463:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:491:32: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:496:35: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:499:44: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:794:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:822:32: Exception check after calling 'predict_sample32' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:827:35: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:830:44: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1333:24: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1337:28: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1341:27: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1344:39: Exception check after calling '_loss' will always require the GIL to be acquired. Declare '_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:704:5: Exception check on 'l1penalty' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:547:31: Exception check after calling 'shuffle' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'shuffle' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'shuffle' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:549:28: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:557:25: Exception check after calling 'dot' will always require the GIL to be acquired. Declare 'dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:564:40: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:575:45: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:578:38: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:580:38: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:602:27: Exception check after calling 'scale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'scale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'scale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:605:25: Exception check after calling 'add' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'add' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:618:33: Exception check after calling 'add_average' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'add_average' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add_average' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:625:29: Exception check after calling 'l1penalty' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\manifold\\_barnes_hut_tsne.pyx:220:30: Exception check after calling 'summarize' will always require the GIL to be acquired. Declare 'summarize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:295:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:303:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:334:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:338:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:433:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:437:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:440:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:443:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:472:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:481:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:484:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:487:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:510:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:543:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:573:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:581:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:584:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:587:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:631:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:639:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:642:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:645:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:694:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:710:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:713:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:716:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:739:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:761:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:784:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:810:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:840:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:864:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:889:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:914:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:938:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:962:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:986:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1020:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1026:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1029:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1032:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1132:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:562:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:570:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:632:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1122:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1131:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1716:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:104:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:120:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:131:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\neighbors\\_binary_tree.pxi:506:5: Exception check on 'dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dual_swap' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          # determine number of levels in the tree, and from this\n",
      "          # the number of nodes in the tree.  This results in leaf nodes\n",
      "          # with numbers of points between leaf_size and 2 * leaf_size\n",
      "          self.n_levels = int(\n",
      "              np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1)\n",
      "          self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                              ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_binary_tree.pxi:982:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'Py_ssize_t')\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1161:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1162:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1286:17: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1418:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1723:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1771:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1772:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1825:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1826:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1921:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1922:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1924:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1925:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2007:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2008:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2094:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2098:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2099:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2100:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2256:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2257:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2262:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2263:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2377:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2378:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2427:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2428:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2429:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2430:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:56:9: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:57:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:58:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:64:24: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:562:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:570:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:632:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1122:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1131:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1716:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:86:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:147:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\neighbors\\_binary_tree.pxi:506:5: Exception check on 'dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dual_swap' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          # determine number of levels in the tree, and from this\n",
      "          # the number of nodes in the tree.  This results in leaf nodes\n",
      "          # with numbers of points between leaf_size and 2 * leaf_size\n",
      "          self.n_levels = int(\n",
      "              np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1)\n",
      "          self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                              ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_binary_tree.pxi:982:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'Py_ssize_t')\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1161:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1162:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1286:17: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1418:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1723:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1771:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1772:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1825:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1826:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1921:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1922:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1924:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1925:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2007:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2008:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2094:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2098:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2099:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2100:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2256:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2257:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2262:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2263:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2377:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2378:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2427:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2428:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2429:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2430:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:47:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:48:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:49:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:50:9: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_kd_tree.pyx\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:116:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:305:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:464:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:559:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:571:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      def __cinit__(self, int n_dimensions, int verbose):\n",
      "          \"\"\"Constructor.\"\"\"\n",
      "          # Parameters of the tree\n",
      "          self.n_dimensions = n_dimensions\n",
      "          self.verbose = verbose\n",
      "          self.n_cells_per_cell = 2 ** self.n_dimensions\n",
      "                                    ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_quad_tree.pyx:56:34: Cannot assign type 'double' to 'SIZE_t' (alias of 'Py_ssize_t')\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_quad_tree.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          free_problem(problem)\n",
      "          free_parameter(param)\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:55:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          free_parameter(param)\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:56:31: Cannot assign type 'void (int, double, double *, int, double *, int) except * nogil' to 'axpy_func' (alias of 'void (*)(int, double, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "      blas_functions.scal = _scal[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:57:31: Cannot assign type 'void (int, double, double *, int) except * nogil' to 'scal_func' (alias of 'void (*)(int, double, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "      blas_functions.scal = _scal[double]\n",
      "      blas_functions.nrm2 = _nrm2[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:58:31: Cannot assign type 'double (int, double *, int) except * nogil' to 'nrm2_func' (alias of 'double (*)(int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_liblinear.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          # for SVR: epsilon is called p in libsvm\n",
      "          error_repl = error_msg.decode('utf-8').replace(\"p < 0\", \"epsilon < 0\")\n",
      "          raise ValueError(error_repl)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:191:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                         class_weight_label.data, class_weight.data)\n",
      "      model = set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,\n",
      "                        support.data, support.shape, sv_coef.strides,\n",
      "                        sv_coef.data, intercept.data, nSV.data, probA.data, probB.data)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:355:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                        sv_coef.data, intercept.data, nSV.data,\n",
      "                        probA.data, probB.data)\n",
      "  \n",
      "      cdef np.npy_intp n_class = get_nr(model)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:461:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          n_class = 1\n",
      "      else:\n",
      "          n_class = get_nr(model)\n",
      "          n_class = n_class * (n_class - 1) // 2\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:567:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef np.ndarray[np.float64_t, ndim=1, mode='c'] target\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:711:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_libsvm.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          free_problem(problem)\n",
      "          free_param(param)\n",
      "          raise ValueError(error_msg)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:153:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                            sv_coef.data, intercept.data,\n",
      "                            nSV.data, probA.data, probB.data)\n",
      "      #TODO: use check_model\n",
      "      dec_values = np.empty(T_indptr.shape[0]-1)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:284:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      #TODO: use check_model\n",
      "      cdef np.npy_intp n_class = get_nr(model)\n",
      "      cdef int rv\n",
      "      dec_values = np.empty((T_indptr.shape[0]-1, n_class), dtype=np.float64)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:343:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          n_class = get_nr(model)\n",
      "          n_class = n_class * (n_class - 1) // 2\n",
      "  \n",
      "      dec_values = np.empty((T_indptr.shape[0] - 1, n_class), dtype=np.float64)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:412:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_libsvm_sparse.pyx\n",
      "  warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:82:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:89:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:96:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:278:76: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:344:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:371:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:398:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:740:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:784:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:795:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:806:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:1028:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:1078:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:1109:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:1137:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:165:30: Exception check after calling 'children_impurity' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'children_impurity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'children_impurity' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:536:44: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:570:49: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:575:50: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1072:89: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1100:74: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1102:62: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1128:75: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1130:63: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1168:70: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1184:69: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1248:74: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1260:75: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1361:32: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1396:56: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1397:58: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1418:44: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1421:45: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:180:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:210:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:264:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:578:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:1096:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:1326:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:42:5: Exception check on '_init_split' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_init_split' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_init_split' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:456:5: Exception check on 'sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sort' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:463:5: Exception check on 'swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:492:5: Exception check on 'introsort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'introsort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'introsort' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:525:5: Exception check on 'sift_down' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'sift_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sift_down' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:548:5: Exception check on 'heapsort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'heapsort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapsort' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:940:5: Exception check on 'binary_search' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'binary_search' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:965:5: Exception check on 'extract_nnz_index_to_samples' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'extract_nnz_index_to_samples' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_index_to_samples' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:1005:5: Exception check on 'extract_nnz_binary_search' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'extract_nnz_binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_binary_search' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:1077:5: Exception check on 'sparse_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'sparse_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sparse_swap' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if not is_samples_sorted[0]:\n",
      "          n_samples = end - start\n",
      "          memcpy(sorted_samples + start, samples + start,\n",
      "                 n_samples * sizeof(SIZE_t))\n",
      "          qsort(sorted_samples + start, n_samples, sizeof(SIZE_t),\n",
      "                compare_SIZE_t)\n",
      "                ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\tree\\_splitter.pyx:1033:14: Cannot assign type 'int (const void *, const void *) except? -1 nogil' to 'int (*)(const void *, const void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of 'compare_SIZE_t'.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\tree\\_splitter.pyx\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:267:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:414:76: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:668:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:680:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:714:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "          # Initial capacity\n",
      "          cdef int init_capacity\n",
      "  \n",
      "          if tree.max_depth <= 10:\n",
      "              init_capacity = (2 ** (tree.max_depth + 1)) - 1\n",
      "                                                          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\tree\\_tree.pyx:146:56: Cannot assign type 'double' to 'int'\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\tree\\_tree.pyx\n",
      "  warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:25:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:110:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:226:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:314:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:331:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:489:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:503:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:25:5: Exception check on 'safe_realloc' will always require the GIL to be acquired. Declare 'safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:55:20: No exception value declared for 'rand_int' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:59:24: No exception value declared for 'rand_uniform' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:63:15: No exception value declared for 'log' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:123:24: Exception check after calling '__pyx_fuse_9safe_realloc' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_9safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:201:27: Exception check after calling 'heapify_up' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'heapify_up' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_up' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:221:29: Exception check after calling 'heapify_down' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'heapify_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_down' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:239:24: Exception check after calling '__pyx_fuse_10safe_realloc' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_10safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:255:23: Exception check after calling 'heapify_up' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'heapify_up' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_up' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:277:29: Exception check after calling 'heapify_down' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'heapify_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_down' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:322:20: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:345:24: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:487:32: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:512:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:513:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:516:47: Exception check after calling 'update_median_parameters_post_push' will always require the GIL to be acquired. Declare 'update_median_parameters_post_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:527:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:547:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:550:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:556:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:559:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:569:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:570:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:572:42: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:573:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:584:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:585:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:588:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:591:39: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:592:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:603:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:610:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:631:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:634:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:641:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:644:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:652:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:653:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:656:52: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:20:5: Exception check on '_dot' will always require the GIL to be acquired. Declare '_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:33:5: Exception check on '_asum' will always require the GIL to be acquired. Declare '_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:45:5: Exception check on '_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:58:5: Exception check on '_nrm2' will always require the GIL to be acquired. Declare '_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:70:5: Exception check on '_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:82:5: Exception check on '_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:94:5: Exception check on '_rotg' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_rotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rotg' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:107:5: Exception check on '_rot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_rot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rot' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:124:5: Exception check on '_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:153:5: Exception check on '_ger' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_ger' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:183:5: Exception check on '_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemm' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          dec(end)\n",
      "          # Construct our arguments\n",
      "          cdef pair[ITYPE_t, DTYPE_t] args\n",
      "          args.first = key\n",
      "          args.second = value\n",
      "          self.my_map.insert(end, args)\n",
      "                             ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\utils\\_fast_dict.pyx:136:27: Cannot assign type 'iterator' to 'const_iterator'\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\utils\\_fast_dict.pyx\n",
      "  warning: sklearn\\utils\\_openmp_helpers.pyx:1:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\utils\\_openmp_helpers.pyx:44:4: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:77:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:78:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:114:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:115:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:402:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:403:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:439:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:440:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:178:29: Exception check after calling 'reset_wscale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'reset_wscale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'reset_wscale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:183:17: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:185:17: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:189:13: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:351:29: Exception check after calling 'reset_wscale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'reset_wscale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'reset_wscale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:356:17: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:358:17: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:362:13: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  Compiling sklearn\\__check_build\\_check_build.pyx because it changed.\n",
      "  Compiling sklearn\\preprocessing\\_csr_polynomial_expansion.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_dbscan_inner.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_hierarchical_fast.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_common.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_lloyd.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_elkan.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_minibatch.pyx because it changed.\n",
      "  Compiling sklearn\\datasets\\_svmlight_format_fast.pyx because it changed.\n",
      "  Compiling sklearn\\decomposition\\_online_lda_fast.pyx because it changed.\n",
      "  Compiling sklearn\\decomposition\\_cdnmf_fast.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_gradient_boosting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx because it changed.\n",
      "  Compiling sklearn\\feature_extraction\\_hashing_fast.pyx because it changed.\n",
      "  Compiling sklearn\\manifold\\_utils.pyx because it changed.\n",
      "  Compiling sklearn\\manifold\\_barnes_hut_tsne.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_fast.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_dist_metrics.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_ball_tree.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_kd_tree.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_partition_nodes.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_quad_tree.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_tree.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_splitter.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_criterion.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_utils.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\sparsefuncs_fast.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_cython_blas.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\arrayfuncs.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\murmurhash.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_fast_dict.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_openmp_helpers.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_seq_dataset.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_weight_vector.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_random.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_logistic_sigmoid.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_readonly_array_wrapper.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_typedefs.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_newrand.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_libsvm.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_liblinear.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_libsvm_sparse.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_cd_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_sgd_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_sag_fast.pyx because it changed.\n",
      "  Compiling sklearn\\_isotonic.pyx because it changed.\n",
      "  multiprocessing.pool.RemoteTraceback:\n",
      "  \"\"\"\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "      result = (True, func(*args, **kwds))\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "      return list(map(*args))\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  \"\"\"\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "  [ 1/55] Cythonizing sklearn\\__check_build\\_check_build.pyx\n",
      "  [ 2/55] Cythonizing sklearn\\_isotonic.pyx\n",
      "  [ 3/55] Cythonizing sklearn\\cluster\\_dbscan_inner.pyx\n",
      "  [ 4/55] Cythonizing sklearn\\cluster\\_hierarchical_fast.pyx\n",
      "  [ 5/55] Cythonizing sklearn\\cluster\\_k_means_common.pyx\n",
      "  [ 6/55] Cythonizing sklearn\\cluster\\_k_means_elkan.pyx\n",
      "  [ 7/55] Cythonizing sklearn\\cluster\\_k_means_lloyd.pyx\n",
      "  [ 8/55] Cythonizing sklearn\\cluster\\_k_means_minibatch.pyx\n",
      "  [ 9/55] Cythonizing sklearn\\datasets\\_svmlight_format_fast.pyx\n",
      "  [10/55] Cythonizing sklearn\\decomposition\\_cdnmf_fast.pyx\n",
      "  [11/55] Cythonizing sklearn\\decomposition\\_online_lda_fast.pyx\n",
      "  [12/55] Cythonizing sklearn\\ensemble\\_gradient_boosting.pyx\n",
      "  [13/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx\n",
      "  [14/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx\n",
      "  [15/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx\n",
      "  [16/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx\n",
      "  [17/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx\n",
      "  [18/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx\n",
      "  [19/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx\n",
      "  [20/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  [21/55] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx\n",
      "  [22/55] Cythonizing sklearn\\feature_extraction\\_hashing_fast.pyx\n",
      "  [23/55] Cythonizing sklearn\\linear_model\\_cd_fast.pyx\n",
      "  [24/55] Cythonizing sklearn\\linear_model\\_sag_fast.pyx\n",
      "  [25/55] Cythonizing sklearn\\linear_model\\_sgd_fast.pyx\n",
      "  [26/55] Cythonizing sklearn\\manifold\\_barnes_hut_tsne.pyx\n",
      "  [27/55] Cythonizing sklearn\\manifold\\_utils.pyx\n",
      "  [28/55] Cythonizing sklearn\\metrics\\_dist_metrics.pyx\n",
      "  [29/55] Cythonizing sklearn\\metrics\\_pairwise_fast.pyx\n",
      "  [30/55] Cythonizing sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx\n",
      "  [31/55] Cythonizing sklearn\\neighbors\\_ball_tree.pyx\n",
      "  [32/55] Cythonizing sklearn\\neighbors\\_kd_tree.pyx\n",
      "  [33/55] Cythonizing sklearn\\neighbors\\_partition_nodes.pyx\n",
      "  [34/55] Cythonizing sklearn\\neighbors\\_quad_tree.pyx\n",
      "  [35/55] Cythonizing sklearn\\preprocessing\\_csr_polynomial_expansion.pyx\n",
      "  [36/55] Cythonizing sklearn\\svm\\_liblinear.pyx\n",
      "  [37/55] Cythonizing sklearn\\svm\\_libsvm.pyx\n",
      "  [38/55] Cythonizing sklearn\\svm\\_libsvm_sparse.pyx\n",
      "  [39/55] Cythonizing sklearn\\svm\\_newrand.pyx\n",
      "  [40/55] Cythonizing sklearn\\tree\\_criterion.pyx\n",
      "  [41/55] Cythonizing sklearn\\tree\\_splitter.pyx\n",
      "  [42/55] Cythonizing sklearn\\tree\\_tree.pyx\n",
      "  [43/55] Cythonizing sklearn\\tree\\_utils.pyx\n",
      "  [44/55] Cythonizing sklearn\\utils\\_cython_blas.pyx\n",
      "  [45/55] Cythonizing sklearn\\utils\\_fast_dict.pyx\n",
      "  [46/55] Cythonizing sklearn\\utils\\_logistic_sigmoid.pyx\n",
      "  [47/55] Cythonizing sklearn\\utils\\_openmp_helpers.pyx\n",
      "  [48/55] Cythonizing sklearn\\utils\\_random.pyx\n",
      "  [49/55] Cythonizing sklearn\\utils\\_readonly_array_wrapper.pyx\n",
      "  [50/55] Cythonizing sklearn\\utils\\_seq_dataset.pyx\n",
      "  [51/55] Cythonizing sklearn\\utils\\_typedefs.pyx\n",
      "  [52/55] Cythonizing sklearn\\utils\\_weight_vector.pyx\n",
      "  [53/55] Cythonizing sklearn\\utils\\arrayfuncs.pyx\n",
      "  [54/55] Cythonizing sklearn\\utils\\murmurhash.pyx\n",
      "  [55/55] Cythonizing sklearn\\utils\\sparsefuncs_fast.pyx\n",
      "      main()\n",
      "    File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 174, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 268, in run_setup\n",
      "      self).run_setup(setup_script=setup_script)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 158, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 319, in <module>\n",
      "      setup_package()\n",
      "    File \"setup.py\", line 315, in setup_package\n",
      "      setup(**metadata)\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 135, in setup\n",
      "      config = configuration()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "    File \"setup.py\", line 201, in configuration\n",
      "      config.add_subpackage(\"sklearn\")\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1050, in add_subpackage\n",
      "      config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1016, in get_subpackage\n",
      "      config = self._get_configuration_from_setup_py(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "      config = setup_module.configuration(*args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-install-cp92_oqz\\scikit-learn_23ce71ed1f5b4201adcb050f8d919750\\sklearn\\setup.py\", line 85, in configuration\n",
      "      cythonize_extensions(top_path, config)\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-install-cp92_oqz\\scikit-learn_23ce71ed1f5b4201adcb050f8d919750\\sklearn\\_build_utils\\__init__.py\", line 78, in cythonize_extensions\n",
      "      config.ext_modules = cythonize(\n",
      "                           ^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\pip-build-env-gt0po1y9\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1145, in cythonize\n",
      "      result.get(99999)  # seconds\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\nitin\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 774, in get\n",
      "      raise self._value\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\nitin\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn==1.2.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (2.2.0)\n",
      "Collecting scikit-learn==1.3.0\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\nitin\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn==1.3.0) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (2.2.0)\n",
      "Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.2 MB 5.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 10.8 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.8/9.2 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.9/9.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.3/9.2 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.6/9.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.4/9.2 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.2 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.2/9.2 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/9.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.6/9.2 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.4/9.2 MB 5.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.6/9.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.2 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.2 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.2 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "Successfully installed scikit-learn-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.2  \n",
    "!pip install scikit-learn==1.2.2  \n",
    "!pip install scikit-learn==1.3.0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba71ef9e-6c56-4b52-8868-904df28eb7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [09/Feb/2025 01:24:41] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Feb/2025 01:24:49] \"POST /check-expense HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = {\n",
    "    \"Engineering\": [\"Travel\", \"Meals\", \"Supplies\"],\n",
    "    \"IT\": [\"Travel\", \"Supplies\"],\n",
    "    \"Finance\": [\"Travel\", \"Meals\"],\n",
    "    \"HR\": [\"Meals\"],\n",
    "    \"Operations\": [\"Travel\", \"Meals\", \"Supplies\"],\n",
    "    \"Sales\": [\"Travel\", \"Meals\"],\n",
    "    \"Marketing\": [\"Travel\", \"Meals\", \"Supplies\"]\n",
    "}\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)\n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.df, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.df = pickle.load(f)\n",
    "    \n",
    "    def check_violation(self, expense):\n",
    "        category = expense.get('category')\n",
    "        department = expense.get('department')\n",
    "        amount = expense.get('amount', 0)\n",
    "        notes = expense.get('notes', \"\").strip()\n",
    "        \n",
    "        violations = []\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category]:\n",
    "            violations.append(f\"Over Budget: {amount} INR exceeds allowed budget of {ALLOWED_BUDGETS[category]} INR.\")\n",
    "        if department in ALLOWED_CATEGORIES and category not in ALLOWED_CATEGORIES[department]:\n",
    "            violations.append(f\"Unauthorized Category: {category} is not allowed for department {department}.\")\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category] and notes == \"\":\n",
    "            violations.append(\"Missing Justification: High amount claimed but justification is missing.\")\n",
    "        \n",
    "        return {\n",
    "            \"expense_id\": expense.get('expense_id', \"N/A\"),\n",
    "            \"employee_id\": expense.get('employee_id', \"N/A\"),\n",
    "            \"category\": category,\n",
    "            \"amount\": amount,\n",
    "            \"violations\": violations if violations else \"No Violations\"\n",
    "        }\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.departments = list(ALLOWED_CATEGORIES.keys())\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'department': np.random.choice(self.departments, n_samples),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'notes': np.random.choice(['Justified', ''], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def rule_based_violation_check(self, row):\n",
    "        cat = row['category']\n",
    "        dept = row['department']\n",
    "        amt = row['amount']\n",
    "        note = row['notes'].strip()\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) * 1.5:\n",
    "            return 1\n",
    "        if dept in ALLOWED_CATEGORIES and cat not in ALLOWED_CATEGORIES[dept]:\n",
    "            return 1\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) and note == \"\":\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "expense_model = ExpenseModel()\n",
    "\n",
    "@app.route('/generate-data', methods=['GET'])\n",
    "def generate_data():\n",
    "    return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    return jsonify(expense_model.check_violation(data))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67cae30e-e6ef-4e63-a223-008ff3b22554",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=4000): Max retries exceeded with url: /check-expense (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001E8D55E1250>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    197\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    199\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[0;32m    200\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[0;32m    201\u001b[0m     )\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    496\u001b[0m         method,\n\u001b[0;32m    497\u001b[0m         url,\n\u001b[0;32m    498\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    499\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    500\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    501\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    502\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    503\u001b[0m         enforce_content_length\u001b[38;5;241m=\u001b[39menforce_content_length,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders()\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1289\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1048\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1051\u001b[0m \n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:986\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connection.py:211\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001E8D55E1250>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    845\u001b[0m )\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=4000): Max retries exceeded with url: /check-expense (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001E8D55E1250>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 24\u001b[0m\n\u001b[0;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://127.0.0.1:4000/check-expense\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpense_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m201\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memployee_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1500\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m }\n\u001b[1;32m---> 24\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, json\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=4000): Max retries exceeded with url: /check-expense (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001E8D55E1250>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:4000/check-expense\"\n",
    "data = {\n",
    "    \"expense_id\": 201,\n",
    "    \"employee_id\": 1500,\n",
    "    \"amount\": 750000,\n",
    "    \"receipt_quality\": 0.65,\n",
    "    \"ocr_confidence\": 0.90,\n",
    "    \"previous_violations\": 1,\n",
    "    \"department\": \"Engineering\",\n",
    "    \"category\": \"Travel\",\n",
    "    \"currency\": \"INR\",\n",
    "    \"vendor_country\": \"US\",\n",
    "    \"payment_method\": \"Credit Card\",\n",
    "    \"expense_date\": \"2024-02-01\",\n",
    "    \"submission_date\": \"2024-02-06\",\n",
    "    \"requires_approval\": 1,\n",
    "    \"has_receipt\": 1,\n",
    "    \"manual_review_required\": 0,\n",
    "    \"notes\": \"\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())  # Print API response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e57090-c516-4c6b-b9de-1fdfe5767ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "Press CTRL+C to quit\n",
      "[2025-02-09 01:23:36,523] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\3520971677.py\", line 79, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1756577180.py\", line 104, in predict_all\n",
      "    pred = self.model.predict(expense_df)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'predict'\n",
      "127.0.0.1 - - [09/Feb/2025 01:23:36] \"POST /check-expense HTTP/1.1\" 500 -\n",
      "[2025-02-09 01:23:54,938] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\3520971677.py\", line 79, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1756577180.py\", line 104, in predict_all\n",
      "    pred = self.model.predict(expense_df)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'predict'\n",
      "127.0.0.1 - - [09/Feb/2025 01:23:54] \"POST /check-expense HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = [\"Travel\", \"Meals\", \"Supplies\", \"Office Supplies\", \"Technology\", \"Training\", \"Entertainment\"]\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)\n",
    "        \n",
    "        # Prepare data for training\n",
    "        features = ['amount', 'receipt_quality', 'ocr_confidence', 'currency', 'vendor_country', 'payment_method']\n",
    "        X = pd.get_dummies(self.df[features])\n",
    "        y = self.df['category'].apply(lambda x: 1 if x not in ALLOWED_CATEGORIES else 0)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "    \n",
    "    def predict_all(self, expense_df):\n",
    "        features = ['amount', 'receipt_quality', 'ocr_confidence', 'currency', 'vendor_country', 'payment_method']\n",
    "        expense_df = pd.get_dummies(expense_df[features]).reindex(columns=self.model.feature_names_in_, fill_value=0)\n",
    "        \n",
    "        predictions = {}\n",
    "        probabilities = {}\n",
    "        for model_name in [\"GradientBoosting Model\"]:\n",
    "            pred = self.model.predict(expense_df)\n",
    "            prob = self.model.predict_proba(expense_df)\n",
    "            predictions[model_name] = pred.tolist()\n",
    "            probabilities[model_name] = prob.tolist()\n",
    "        return predictions, probabilities\n",
    "\n",
    "def _check_compliance(expense):\n",
    "    flags = {}\n",
    "    cat = expense.get('category')\n",
    "    amt = expense.get('amount', 0)\n",
    "    description = expense.get('description', \"\").strip()\n",
    "    \n",
    "    if cat in ALLOWED_BUDGETS and amt > ALLOWED_BUDGETS[cat]:\n",
    "        flags['Over Budget'] = f\"Amount {amt} exceeds budget {ALLOWED_BUDGETS[cat]} for {cat}\"\n",
    "    if cat not in ALLOWED_CATEGORIES:\n",
    "        flags['Unauthorized Category'] = f\"Category {cat} is not authorized\"\n",
    "    if cat in ALLOWED_BUDGETS and amt > ALLOWED_BUDGETS[cat] and not description:\n",
    "        flags['Missing Justification'] = \"High amount claimed without justification\"\n",
    "    \n",
    "    return flags\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    df_new = pd.DataFrame([data])\n",
    "    predictions, probabilities = expense_model.predict_all(df_new)\n",
    "    compliance_flags = _check_compliance(data)\n",
    "    response = {\n",
    "        \"expense_validation\": {\n",
    "            \"ml_predictions\": {\n",
    "                \"predictions\": {\n",
    "                    model: \"Violation\" if pred[0] == 1 else \"Normal\"\n",
    "                    for model, pred in predictions.items()\n",
    "                },\n",
    "                \"confidences\": {\n",
    "                    model: round(max(prob[0]) * 100, 2)\n",
    "                    for model, prob in probabilities.items()\n",
    "                }\n",
    "            },\n",
    "            \"rule_based_checks\": compliance_flags if compliance_flags else \"No Violations\",\n",
    "            \"overall_status\": \"Violation\" if compliance_flags or any(p[0] == 1 for p in predictions.values()) else \"Normal\"\n",
    "        }\n",
    "    }\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167fe13c-ed54-4905-b96b-68b1f087e42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1e9d8-62dc-41b7-971a-d3c65fb20973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2b635-d1e5-4bbb-97b9-f504cac11d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91810769-752f-42da-b072-50d7e2f35346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [09/Feb/2025 00:32:51] \"POST /generate-data HTTP/1.1\" 405 -\n",
      "127.0.0.1 - - [09/Feb/2025 00:32:56] \"GET /generate-data HTTP/1.1\" 200 -\n",
      "[2025-02-09 00:33:04,327] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_31720\\661625177.py\", line 91, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_31720\\661625177.py\", line 56, in predict_all\n",
      "    pred = self.model.predict(expense_df)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'predict'\n",
      "127.0.0.1 - - [09/Feb/2025 00:33:04] \"POST /check-expense HTTP/1.1\" 500 -\n",
      "[2025-02-09 00:33:35,544] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_31720\\661625177.py\", line 91, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_31720\\661625177.py\", line 56, in predict_all\n",
      "    pred = self.model.predict(expense_df)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'predict'\n",
      "127.0.0.1 - - [09/Feb/2025 00:33:35] \"POST /check-expense HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4b487-2e76-46f0-97e5-54c8c0f5d836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac5973-387e-4f2e-ab6a-8357ae8a4d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b5399-3780-4060-8a50-ad03a55d7b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504a2c2-cb26-4366-9e35-3d73bac63e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863b899-6483-4c7b-9b44-e6d6b2f8e23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a07c46d-d52a-4864-a8fc-1ecc2d2b3218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = {\n",
    "    \"Engineering\": [\"Travel\", \"Meals\", \"Supplies\"],\n",
    "    \"IT\": [\"Travel\", \"Supplies\"],\n",
    "    \"Finance\": [\"Travel\", \"Meals\"],\n",
    "    \"HR\": [\"Meals\"],\n",
    "    \"Operations\": [\"Travel\", \"Meals\", \"Supplies\"],\n",
    "    \"Sales\": [\"Travel\", \"Meals\"],\n",
    "    \"Marketing\": [\"Travel\", \"Meals\", \"Supplies\"]\n",
    "}\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)\n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.df, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.df = pickle.load(f)\n",
    "    \n",
    "    def check_violation(self, expense):\n",
    "        category = expense.get('category')\n",
    "        department = expense.get('department')\n",
    "        amount = expense.get('amount', 0)\n",
    "        notes = expense.get('notes', \"\").strip()\n",
    "        \n",
    "        violations = []\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category]:\n",
    "            violations.append(f\"Over Budget: {amount} INR exceeds allowed budget of {ALLOWED_BUDGETS[category]} INR.\")\n",
    "        if department in ALLOWED_CATEGORIES and category not in ALLOWED_CATEGORIES[department]:\n",
    "            violations.append(f\"Unauthorized Category: {category} is not allowed for department {department}.\")\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category] and notes == \"\":\n",
    "            violations.append(\"Missing Justification: High amount claimed but justification is missing.\")\n",
    "        \n",
    "        return {\n",
    "            \"expense_id\": expense.get('expense_id', \"N/A\"),\n",
    "            \"employee_id\": expense.get('employee_id', \"N/A\"),\n",
    "            \"category\": category,\n",
    "            \"amount\": amount,\n",
    "            \"violations\": violations if violations else \"No Violations\"\n",
    "        }\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.departments = list(ALLOWED_CATEGORIES.keys())\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'department': np.random.choice(self.departments, n_samples),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'description': np.random.choice(['Justified', ''], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def rule_based_violation_check(self, row):\n",
    "        cat = row['category']\n",
    "        dept = row['department']\n",
    "        amt = row['amount']\n",
    "        note = row['notes'].strip()\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) * 1.5:\n",
    "            return 1\n",
    "        if dept in ALLOWED_CATEGORIES and cat not in ALLOWED_CATEGORIES[dept]:\n",
    "            return 1\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) and note == \"\":\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "expense_model = ExpenseModel()\n",
    "\n",
    "@app.route('/generate-data', methods=['GET'])\n",
    "def generate_data():\n",
    "    return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    return jsonify(expense_model.check_violation(data))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ab740-47ac-40f3-96db-fafc6d1f1e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4709e9-d6b4-467e-a4f5-67e0e207a816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ddd73-f594-458c-a07d-66ab6128be93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958f512-e3cf-4d93-b611-17d4c2e0ca95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de709e0-f7ee-4a17-b226-af4912452d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Loaded object is not a trained model. Retrain using /generate-data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 162\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jsonify(response)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 162\u001b[0m     expense_model \u001b[38;5;241m=\u001b[39m ExpenseModel()\n\u001b[0;32m    163\u001b[0m     app\u001b[38;5;241m.\u001b[39mrun(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[11], line 58\u001b[0m, in \u001b[0;36mExpenseModel.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(MODEL_FILE):\n\u001b[1;32m---> 58\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_model()\n",
      "Cell \u001b[1;32mIn[11], line 85\u001b[0m, in \u001b[0;36mExpenseModel.load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Ensure the loaded model is a valid scikit-learn model\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 85\u001b[0m            \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded object is not a trained model. Retrain using /generate-data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Load synthetic data used during training\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(DATA_FILE):\n",
      "\u001b[1;31mValueError\u001b[0m: Loaded object is not a trained model. Retrain using /generate-data."
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = [\"Travel\", \"Meals\", \"Supplies\", \"Office Supplies\", \"Technology\", \"Training\", \"Entertainment\"]\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'description': np.random.choice(['Justified', ''], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def rule_based_violation_check(self, row):\n",
    "        cat = row['category']\n",
    "        amt = row['amount']\n",
    "        desc = row['description'].strip()\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) * 1.5:\n",
    "            return 1\n",
    "        if cat not in ALLOWED_CATEGORIES:\n",
    "            return 1\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) and desc == \"\":\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)\n",
    "        \n",
    "        # Prepare data for training\n",
    "        features = ['amount', 'currency', 'vendor_country', 'payment_method']\n",
    "        X = pd.get_dummies(self.df[features])\n",
    "        y = self.df['category'].apply(lambda x: 1 if x not in ALLOWED_CATEGORIES else 0)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "          pickle.dump(self.model, f)\n",
    "        \n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "\n",
    "    # Ensure the loaded model is a valid scikit-learn model\n",
    "        if not hasattr(self.model, \"predict\"):\n",
    "               raise ValueError(\"Loaded object is not a trained model. Retrain using /generate-data.\")\n",
    "\n",
    "    # Load synthetic data used during training\n",
    "        if os.path.exists(DATA_FILE):\n",
    "                self.df = pd.read_csv(DATA_FILE)\n",
    "        else:\n",
    "             raise FileNotFoundError(\"Training data file not found. Please run /generate-data first.\")\n",
    "\n",
    "    \n",
    "    def predict_all(self, expense_df):\n",
    "        features = ['amount', 'currency', 'vendor_country', 'payment_method']\n",
    "        expense_df = pd.get_dummies(expense_df[features])\n",
    "        \n",
    "        # Ensure all required features are present in the input data\n",
    "        model_features = self.df[features].columns.tolist()\n",
    "        missing_cols = set(model_features) - set(expense_df.columns)\n",
    "        for col in missing_cols:\n",
    "            expense_df[col] = 0\n",
    "        \n",
    "        expense_df = expense_df.reindex(columns=model_features, fill_value=0)\n",
    "        \n",
    "        predictions = {}\n",
    "        probabilities = {}\n",
    "        for model_name in [\"GradientBoosting Model\"]:\n",
    "            pred = self.model.predict(expense_df)\n",
    "            prob = self.model.predict_proba(expense_df)\n",
    "            predictions[model_name] = pred.tolist()\n",
    "            probabilities[model_name] = prob.tolist()\n",
    "        return predictions, probabilities\n",
    "\n",
    "def _check_compliance(expense):\n",
    "    flags = {}\n",
    "    cat = expense.get('category')\n",
    "    amt = expense.get('amount', 0)\n",
    "    description = expense.get('description', \"\").strip()\n",
    "    \n",
    "    if cat in ALLOWED_BUDGETS and amt > ALLOWED_BUDGETS[cat]:\n",
    "        flags['Over Budget'] = f\"Amount {amt} exceeds budget {ALLOWED_BUDGETS[cat]} for {cat}\"\n",
    "    if cat not in ALLOWED_CATEGORIES:\n",
    "        flags['Unauthorized Category'] = f\"Category {cat} is not authorized\"\n",
    "    if cat in ALLOWED_BUDGETS and amt > ALLOWED_BUDGETS[cat] and not description:\n",
    "        flags['Missing Justification'] = \"High amount claimed without justification\"\n",
    "    \n",
    "    return flags\n",
    "\n",
    "# @app.route('/generate-data', methods=['GET'])\n",
    "# def generate_data():\n",
    "#     generator = SyntheticDataGenerator()\n",
    "#     df = generator.generate_data(n_samples=1000)\n",
    "#     df.to_csv(DATA_FILE, index=False)\n",
    "#     return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    df_new = pd.DataFrame([data])\n",
    "    predictions, probabilities = expense_model.predict_all(df_new)\n",
    "    compliance_flags = _check_compliance(data)\n",
    "    response = {\n",
    "        \"expense_validation\": {\n",
    "            \"ml_predictions\": {\n",
    "                \"predictions\": {\n",
    "                    model: \"Violation\" if pred[0] == 1 else \"Normal\"\n",
    "                    for model, pred in predictions.items()\n",
    "                },\n",
    "                \"confidences\": {\n",
    "                    model: round(max(prob[0]) * 100, 2)\n",
    "                    for model, prob in probabilities.items()\n",
    "                }\n",
    "            },\n",
    "            \"rule_based_checks\": compliance_flags if compliance_flags else \"No Violations\",\n",
    "            \"overall_status\": \"Violation\" if compliance_flags or any(p[0] == 1 for p in predictions.values()) else \"Normal\"\n",
    "        }\n",
    "    }\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    expense_model = ExpenseModel()\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a9399e3-a290-4f8a-8c93-0da77457aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [09/Feb/2025 01:27:22] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Feb/2025 01:27:31] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Feb/2025 01:27:47] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Feb/2025 01:28:14] \"POST /check-expense HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = [\"Travel\", \"Meals\", \"Supplies\", \"Office Supplies\", \"Technology\", \"Training\", \"Entertainment\"]\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)\n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.df, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.df = pickle.load(f)\n",
    "    \n",
    "    def check_violation(self, expense):\n",
    "        category = expense.get('category')\n",
    "        amount = expense.get('amount', 0)\n",
    "        description = expense.get('description', \"\").strip()\n",
    "        \n",
    "        violations = []\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category]:\n",
    "            violations.append(f\"Over Budget: {amount} INR exceeds allowed budget of {ALLOWED_BUDGETS[category]} INR.\")\n",
    "        if category not in ALLOWED_CATEGORIES:\n",
    "            violations.append(f\"Unauthorized Category: {category} is not allowed.\")\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category] and description.lower() == \"no description\":\n",
    "            violations.append(\"Missing Justification: High amount claimed but justification is missing.\")\n",
    "        \n",
    "        return {\n",
    "            \"expense_id\": expense.get('expense_id', \"N/A\"),\n",
    "            \"employee_id\": expense.get('employee_id', \"N/A\"),\n",
    "            \"category\": category,\n",
    "            \"amount\": amount,\n",
    "            \"violations\": violations if violations else \"No Violations\"\n",
    "        }\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'description': np.random.choice(['Justified', 'no description'], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def rule_based_violation_check(self, row):\n",
    "        cat = row['category']\n",
    "        amt = row['amount']\n",
    "        description = row['description'].strip()\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) * 1.5:\n",
    "            return 1\n",
    "        if cat not in ALLOWED_CATEGORIES:\n",
    "            return 1\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) and description.lower() == \"no description\":\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "expense_model = ExpenseModel()\n",
    "\n",
    "@app.route('/generate-data', methods=['GET'])\n",
    "def generate_data():\n",
    "    return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    return jsonify(expense_model.check_violation(data))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a85b53f8-dd86-4f70-9f2c-63a107d65da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [09/Feb/2025 01:30:07] \"GET /generate-data HTTP/1.1\" 200 -\n",
      "[2025-02-09 01:30:09,927] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1543617587.py\", line 139, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1543617587.py\", line 54, in predict_all\n",
      "    model_features = self.df[features].columns.tolist()\n",
      "                     ^^^^^^^\n",
      "AttributeError: 'ExpenseModel' object has no attribute 'df'\n",
      "127.0.0.1 - - [09/Feb/2025 01:30:09] \"POST /check-expense HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = [\"Travel\", \"Meals\", \"Supplies\", \"Office Supplies\", \"Technology\", \"Training\", \"Entertainment\"]\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)\n",
    "        \n",
    "        # Prepare data for training\n",
    "        features = ['amount', 'currency', 'vendor_country', 'payment_method']\n",
    "        X = pd.get_dummies(self.df[features])\n",
    "        y = self.df['category'].apply(lambda x: 1 if x not in ALLOWED_CATEGORIES else 0)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "    \n",
    "    def predict_all(self, expense_df):\n",
    "        features = ['amount', 'currency', 'vendor_country', 'payment_method']\n",
    "        expense_df = pd.get_dummies(expense_df[features])\n",
    "        \n",
    "        # Ensure all required features are present in the input data\n",
    "        model_features = getattr(self.model, \"feature_names_in_\", None)\n",
    "        if model_features is None:\n",
    "            model_features = self.df[features].columns.tolist()\n",
    "        \n",
    "        missing_cols = set(model_features) - set(expense_df.columns)\n",
    "        for col in missing_cols:\n",
    "            expense_df[col] = 0\n",
    "        \n",
    "        expense_df = expense_df.reindex(columns=model_features, fill_value=0)\n",
    "        \n",
    "        predictions = {}\n",
    "        probabilities = {}\n",
    "        for model_name in [\"GradientBoosting Model\"]:\n",
    "            pred = self.model.predict(expense_df)\n",
    "            prob = self.model.predict_proba(expense_df)\n",
    "            predictions[model_name] = pred.tolist()\n",
    "            probabilities[model_name] = prob.tolist()\n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def check_violation(self, expense):\n",
    "        category = expense.get('category')\n",
    "        amount = expense.get('amount', 0)\n",
    "        description = expense.get('description', \"\").strip()\n",
    "        \n",
    "        violations = []\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category]:\n",
    "            violations.append(f\"Over Budget: {amount} INR exceeds allowed budget of {ALLOWED_BUDGETS[category]} INR.\")\n",
    "        if category not in ALLOWED_CATEGORIES:\n",
    "            violations.append(f\"Unauthorized Category: {category} is not allowed.\")\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category] and description.lower() == \"no description\":\n",
    "            violations.append(\"Missing Justification: High amount claimed but justification is missing.\")\n",
    "        \n",
    "        return {\n",
    "            \"expense_id\": expense.get('expense_id', \"N/A\"),\n",
    "            \"employee_id\": expense.get('employee_id', \"N/A\"),\n",
    "            \"category\": category,\n",
    "            \"amount\": amount,\n",
    "            \"violations\": violations if violations else \"No Violations\"\n",
    "        }\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'description': np.random.choice(['Justified', 'no description'], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def rule_based_violation_check(self, row):\n",
    "        cat = row['category']\n",
    "        amt = row['amount']\n",
    "        description = row['description'].strip()\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) * 1.5:\n",
    "            return 1\n",
    "        if cat not in ALLOWED_CATEGORIES:\n",
    "            return 1\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) and description.lower() == \"no description\":\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "expense_model = ExpenseModel()\n",
    "\n",
    "@app.route('/generate-data', methods=['GET'])\n",
    "def generate_data():\n",
    "    return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    df_new = pd.DataFrame([data])\n",
    "    predictions, probabilities = expense_model.predict_all(df_new)\n",
    "    compliance_flags = expense_model.check_violation(data)\n",
    "    response = {\n",
    "        \"expense_validation\": {\n",
    "            \"ml_predictions\": predictions,\n",
    "            \"probabilities\": probabilities,\n",
    "            \"rule_based_checks\": compliance_flags\n",
    "        }\n",
    "    }\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3742a701-5a4b-4a1f-b594-f8783c185ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [09/Feb/2025 01:32:30] \"GET /generate-data HTTP/1.1\" 200 -\n",
      "[2025-02-09 01:32:34,681] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1208711872.py\", line 133, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1208711872.py\", line 71, in predict_all\n",
      "    pred = self.model.predict(expense_df)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'predict'\n",
      "127.0.0.1 - - [09/Feb/2025 01:32:34] \"POST /check-expense HTTP/1.1\" 500 -\n",
      "[2025-02-09 01:32:36,396] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1208711872.py\", line 133, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1208711872.py\", line 71, in predict_all\n",
      "    pred = self.model.predict(expense_df)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'predict'\n",
      "127.0.0.1 - - [09/Feb/2025 01:32:36] \"POST /check-expense HTTP/1.1\" 500 -\n",
      "[2025-02-09 01:32:38,547] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1208711872.py\", line 133, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1208711872.py\", line 71, in predict_all\n",
      "    pred = self.model.predict(expense_df)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'predict'\n",
      "127.0.0.1 - - [09/Feb/2025 01:32:38] \"POST /check-expense HTTP/1.1\" 500 -\n",
      "[2025-02-09 01:32:38,965] ERROR in app: Exception on /check-expense [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1208711872.py\", line 133, in check_expense\n",
      "    predictions, probabilities = expense_model.predict_all(df_new)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\AppData\\Local\\Temp\\ipykernel_8568\\1208711872.py\", line 71, in predict_all\n",
      "    pred = self.model.predict(expense_df)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nitin\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'predict'\n",
      "127.0.0.1 - - [09/Feb/2025 01:32:38] \"POST /check-expense HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = [\"Travel\", \"Meals\", \"Supplies\", \"Office Supplies\", \"Technology\", \"Training\", \"Entertainment\"]\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            try:\n",
    "                self.load_model()\n",
    "                self.df = pd.read_csv(DATA_FILE)  # Ensure self.df exists after loading\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model: {e}. Retraining model...\")\n",
    "                self.train_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)  # Save dataset for later use\n",
    "        self.feature_columns = list(pd.get_dummies(self.df[['amount', 'currency', 'vendor_country', 'payment_method']]).columns)  # Store features\n",
    "        \n",
    "        # Prepare data for training\n",
    "        features = ['amount', 'currency', 'vendor_country', 'payment_method']\n",
    "        X = pd.get_dummies(self.df[features]).reindex(columns=self.feature_columns, fill_value=0)\n",
    "        y = self.df['category'].apply(lambda x: 1 if x not in ALLOWED_CATEGORIES else 0)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        self.df = pd.read_csv(DATA_FILE)  # Ensure self.df exists after loading\n",
    "    \n",
    "    def predict_all(self, expense_df):\n",
    "        features = ['amount', 'currency', 'vendor_country', 'payment_method']\n",
    "        expense_df = pd.get_dummies(expense_df[features])\n",
    "        \n",
    "        if not hasattr(self, \"feature_columns\"):\n",
    "            self.feature_columns = list(pd.get_dummies(self.df[['amount', 'currency', 'vendor_country', 'payment_method']]).columns)\n",
    "        \n",
    "        model_features = self.feature_columns\n",
    "        missing_cols = set(model_features) - set(expense_df.columns)\n",
    "        for col in missing_cols:\n",
    "            expense_df[col] = 0\n",
    "        \n",
    "        expense_df = expense_df.reindex(columns=model_features, fill_value=0)\n",
    "        \n",
    "        predictions = {}\n",
    "        probabilities = {}\n",
    "        for model_name in [\"GradientBoosting Model\"]:\n",
    "            pred = self.model.predict(expense_df)\n",
    "            prob = self.model.predict_proba(expense_df)\n",
    "            predictions[model_name] = pred.tolist()\n",
    "            probabilities[model_name] = prob.tolist()\n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def check_violation(self, expense):\n",
    "        category = expense.get('category')\n",
    "        amount = expense.get('amount', 0)\n",
    "        description = expense.get('description', \"\").strip()\n",
    "        \n",
    "        violations = []\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category]:\n",
    "            violations.append(f\"Over Budget: {amount} INR exceeds allowed budget of {ALLOWED_BUDGETS[category]} INR.\")\n",
    "        if category not in ALLOWED_CATEGORIES:\n",
    "            violations.append(f\"Unauthorized Category: {category} is not allowed.\")\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category] and description.lower() == \"no description\":\n",
    "            violations.append(\"Missing Justification: High amount claimed but justification is missing.\")\n",
    "        \n",
    "        return {\n",
    "            \"expense_id\": expense.get('expense_id', \"N/A\"),\n",
    "            \"employee_id\": expense.get('employee_id', \"N/A\"),\n",
    "            \"category\": category,\n",
    "            \"amount\": amount,\n",
    "            \"violations\": violations if violations else \"No Violations\"\n",
    "        }\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'description': np.random.choice(['Justified', 'no description'], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "\n",
    "expense_model = ExpenseModel()\n",
    "\n",
    "@app.route('/generate-data', methods=['GET'])\n",
    "def generate_data():\n",
    "    return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    df_new = pd.DataFrame([data])\n",
    "    predictions, probabilities = expense_model.predict_all(df_new)\n",
    "    compliance_flags = expense_model.check_violation(data)\n",
    "    response = {\n",
    "        \"expense_validation\": {\n",
    "            \"ml_predictions\": predictions,\n",
    "            \"probabilities\": probabilities,\n",
    "            \"rule_based_checks\": compliance_flags\n",
    "        }\n",
    "    }\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac3234d8-f7b9-407d-95f8-879001bc1d5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:37\u001b[1;36m\u001b[0m\n\u001b[1;33m    description = expense.get(\"description\", \"\").strip()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = [\"Travel\", \"Meals\", \"Supplies\", \"Office Supplies\", \"Technology\", \"Training\", \"Entertainment\"]\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            try:\n",
    "                self.load_model()\n",
    "                self.df = pd.read_csv(DATA_FILE)  # Ensure self.df exists after loading\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model: {e}. Retraining model...\")\n",
    "                self.train_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)  # Save dataset for later use\n",
    "        self.feature_columns = list(pd.get_dummies(self.df[['amount', 'currency', 'vendor_country', 'payment_method']]).columns)  # Store features\n",
    "        \n",
    "        # Prepare data for training\n",
    "        features = ['amount', 'currency', 'vendor_country', 'payment_method']\n",
    "        X = pd.get_dummies(self.df[features]).reindex(columns=self.feature_columns, fill_value=0)\n",
    "        y = self.df['category'].apply(lambda x: 1 if x not in ALLOWED_CATEGORIES else 0)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        self.df = pd.read_csv(DATA_FILE)  # Ensure self.df exists after loading\n",
    "    \n",
    "    def predict_all(self, expense_df):\n",
    "        features = ['amount', 'currency', 'vendor_country', 'payment_method']\n",
    "        expense_df = pd.get_dummies(expense_df[features])\n",
    "        \n",
    "        if not hasattr(self, \"feature_columns\"):\n",
    "            self.feature_columns = list(pd.get_dummies(self.df[['amount', 'currency', 'vendor_country', 'payment_method']]).columns)\n",
    "        \n",
    "        model_features = self.feature_columns\n",
    "        missing_cols = set(model_features) - set(expense_df.columns)\n",
    "        for col in missing_cols:\n",
    "            expense_df[col] = 0\n",
    "        \n",
    "        expense_df = expense_df.reindex(columns=model_features, fill_value=0)\n",
    "        \n",
    "        predictions = {}\n",
    "        probabilities = {}\n",
    "        for model_name in [\"GradientBoosting Model\"]:\n",
    "            pred = self.model.predict(expense_df)\n",
    "            prob = self.model.predict_proba(expense_df)\n",
    "            predictions[model_name] = pred.tolist()\n",
    "            probabilities[model_name] = prob.tolist()\n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def check_violation(self, expense):\n",
    "        category = expense.get('category')\n",
    "        amount = expense.get('amount', 0)\n",
    "        description = expense.get('description', \"\").strip()\n",
    "        \n",
    "        violations = []\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category]:\n",
    "            violations.append(f\"Over Budget: {amount} INR exceeds allowed budget of {ALLOWED_BUDGETS[category]} INR.\")\n",
    "        if category not in ALLOWED_CATEGORIES:\n",
    "            violations.append(f\"Unauthorized Category: {category} is not allowed.\")\n",
    "        if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category] and description.lower() == \"no description\":\n",
    "            violations.append(\"Missing Justification: High amount claimed but justification is missing.\")\n",
    "        \n",
    "        return {\n",
    "            \"expense_id\": expense.get('expense_id', \"N/A\"),\n",
    "            \"employee_id\": expense.get('employee_id', \"N/A\"),\n",
    "            \"category\": category,\n",
    "            \"amount\": amount,\n",
    "            \"violations\": violations if violations else \"No Violations\"\n",
    "        }\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'description': np.random.choice(['Justified', 'no description'], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "\n",
    "expense_model = ExpenseModel()\n",
    "\n",
    "@app.route('/generate-data', methods=['GET'])\n",
    "def generate_data():\n",
    "    return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    df_new = pd.DataFrame([data])\n",
    "    predictions, probabilities = expense_model.predict_all(df_new)\n",
    "    compliance_flags = expense_model.check_violation(data)\n",
    "    response = {\n",
    "        \"expense_validation\": {\n",
    "            \"ml_predictions\": predictions,\n",
    "            \"probabilities\": probabilities,\n",
    "            \"rule_based_checks\": compliance_flags\n",
    "        }\n",
    "    }\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b04b7081-0869-430f-a387-f73220a291dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:37\u001b[1;36m\u001b[0m\n\u001b[1;33m    description = expense.get(\"description\", \"\").strip()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3355bb-dfd5-4847-9f61-88984bece3f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:37\u001b[1;36m\u001b[0m\n\u001b[1;33m    description = expense.get(\"description\", \"\").strip()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = [\"Travel\", \"Meals\", \"Supplies\", \"Office Supplies\", \"Technology\", \"Training\", \"Entertainment\"]\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)\n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.df, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.df = pickle.load(f)\n",
    "    def check_violation(self, expense):\n",
    "           category = expense.get(\"category\")\n",
    "           amount = expense.get(\"amount\", 0)\n",
    "          description = expense.get(\"description\", \"\").strip()\n",
    "    \n",
    "          violations = []\n",
    "            if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category]:\n",
    "                  violations.append(f\"Over Budget: {amount} INR exceeds allowed budget of {ALLOWED_BUDGETS[category]} INR.\")\n",
    "            if category not in ALLOWED_CATEGORIES:\n",
    "                   violations.append(f\"Unauthorized Category: {category} is not allowed.\")\n",
    "            if category in ALLOWED_BUDGETS and amount > ALLOWED_BUDGETS[category] and description.lower() == \"no description\":\n",
    "                 violations.append(\"Missing Justification: High amount claimed but justification is missing.\")\n",
    "\n",
    "    # Create the validation result\n",
    "           violation_data = {\n",
    "                    \"expense_id\": expense.get(\"expense_id\", \"N/A\"),\n",
    "                   \"employee_id\": expense.get(\"employee_id\", \"N/A\"),\n",
    "                    \"category\": category,\n",
    "                     \"amount\": amount,\n",
    "                    \"violations\": violations if violations else \"No Violations\",\n",
    "                        }\n",
    "\n",
    "    # Append the validation data to the original expense dictionary\n",
    "                   expense.update(violation_data)  # This ensures it is added to the same dictionary\n",
    "\n",
    "              return violation_data  # You can still return it for debugging or logging purposes\n",
    "\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'description': np.random.choice(['Justified', 'no description'], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def rule_based_violation_check(self, row):\n",
    "        cat = row['category']\n",
    "        amt = row['amount']\n",
    "        description = row['description'].strip()\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) * 1.5:\n",
    "            return 1\n",
    "        if cat not in ALLOWED_CATEGORIES:\n",
    "            return 1\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) and description.lower() == \"no description\":\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "expense_model = ExpenseModel()\n",
    "\n",
    "@app.route('/generate-data', methods=['GET'])\n",
    "def generate_data():\n",
    "    return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    data = request.json\n",
    "    return jsonify(expense_model.check_violation(data))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7b767-9cc8-46ba-8f4a-2f62a8915fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://10.120.97.67:4000\n",
      "Press CTRL+C to quit\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 07:58:27.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_uf7RO5NrvSqG9dTMs6Ce70L1\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_uf7RO5NrvSqG9dTMs6Ce70L1/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 07:58:27.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_uf7RO5NrvSqG9dTMs6Ce70L1/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 07:58:28.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_QxqnhD66nkrOigxHIWjHQteh\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_uf7RO5NrvSqG9dTMs6Ce70L1/runs/run_QxqnhD66nkrOigxHIWjHQteh \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_uf7RO5NrvSqG9dTMs6Ce70L1/runs/run_QxqnhD66nkrOigxHIWjHQteh \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_uf7RO5NrvSqG9dTMs6Ce70L1/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 07:58:31.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 07:58:31] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 07:58:31] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:00:34.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_YruWIuiFdmMFIy94WZTak0tl\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_YruWIuiFdmMFIy94WZTak0tl/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:00:34.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_YruWIuiFdmMFIy94WZTak0tl/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:00:35.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_sEyYOrMpInQA39sNPeVCDzey\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_YruWIuiFdmMFIy94WZTak0tl/runs/run_sEyYOrMpInQA39sNPeVCDzey \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_YruWIuiFdmMFIy94WZTak0tl/runs/run_sEyYOrMpInQA39sNPeVCDzey \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_YruWIuiFdmMFIy94WZTak0tl/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:00:38.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 08:00:38] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 08:00:38] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:29:22.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_ALgPOKPAty0L5W6vu2VRnwMw\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_ALgPOKPAty0L5W6vu2VRnwMw/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:29:22.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_ALgPOKPAty0L5W6vu2VRnwMw/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:29:23.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_yqP2YHIMTeScWy6iXgovCIfm\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_ALgPOKPAty0L5W6vu2VRnwMw/runs/run_yqP2YHIMTeScWy6iXgovCIfm \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_ALgPOKPAty0L5W6vu2VRnwMw/runs/run_yqP2YHIMTeScWy6iXgovCIfm \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_ALgPOKPAty0L5W6vu2VRnwMw/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:29:25.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 08:29:25] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 08:29:25] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:43:20.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_0sFo1BJuFeWmEfrJg53UDxYI\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_0sFo1BJuFeWmEfrJg53UDxYI/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:43:21.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_0sFo1BJuFeWmEfrJg53UDxYI/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:43:25.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_folx2vNS5Jp6cx337L4Hh4qs\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_0sFo1BJuFeWmEfrJg53UDxYI/runs/run_folx2vNS5Jp6cx337L4Hh4qs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_0sFo1BJuFeWmEfrJg53UDxYI/runs/run_folx2vNS5Jp6cx337L4Hh4qs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_0sFo1BJuFeWmEfrJg53UDxYI/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:43:27.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 08:43:27] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 08:43:27] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:49:28.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_fRlvB7s8OH3WywjoPo6AWCTZ\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_fRlvB7s8OH3WywjoPo6AWCTZ/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:49:29.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_fRlvB7s8OH3WywjoPo6AWCTZ/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:49:29.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_lF7Di8uRPS7dGxsNHCPeh0Am\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_fRlvB7s8OH3WywjoPo6AWCTZ/runs/run_lF7Di8uRPS7dGxsNHCPeh0Am \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_fRlvB7s8OH3WywjoPo6AWCTZ/runs/run_lF7Di8uRPS7dGxsNHCPeh0Am \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_fRlvB7s8OH3WywjoPo6AWCTZ/runs/run_lF7Di8uRPS7dGxsNHCPeh0Am \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_fRlvB7s8OH3WywjoPo6AWCTZ/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:49:33.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 08:49:33] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 08:49:33] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:52:00.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_lJhcAojEoLCdkgkOjSOjMD25\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_lJhcAojEoLCdkgkOjSOjMD25/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:52:00.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_lJhcAojEoLCdkgkOjSOjMD25/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:52:02.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_OYiDyYM0Y9Z3vQQCcPFvk7Hu\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_lJhcAojEoLCdkgkOjSOjMD25/runs/run_OYiDyYM0Y9Z3vQQCcPFvk7Hu \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_lJhcAojEoLCdkgkOjSOjMD25/runs/run_OYiDyYM0Y9Z3vQQCcPFvk7Hu \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_lJhcAojEoLCdkgkOjSOjMD25/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:52:04.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 08:52:04] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 08:52:04] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:57:09.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_O43xohe2mAJpIeXEmgHINeml\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_O43xohe2mAJpIeXEmgHINeml/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:57:09.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_O43xohe2mAJpIeXEmgHINeml/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:57:13.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_gfIRkKtjKZ7JlEua9brreC3e\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_O43xohe2mAJpIeXEmgHINeml/runs/run_gfIRkKtjKZ7JlEua9brreC3e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_O43xohe2mAJpIeXEmgHINeml/runs/run_gfIRkKtjKZ7JlEua9brreC3e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_O43xohe2mAJpIeXEmgHINeml/runs/run_gfIRkKtjKZ7JlEua9brreC3e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_O43xohe2mAJpIeXEmgHINeml/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 08:57:16.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 08:57:16] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 08:57:16] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:07:38.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_H7liwxlTJQFhzFcbfEzAsJU3\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_H7liwxlTJQFhzFcbfEzAsJU3/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:07:39.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_H7liwxlTJQFhzFcbfEzAsJU3/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:07:42.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_Ibq6ozs8rdRqciEeN536AFZ4\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_H7liwxlTJQFhzFcbfEzAsJU3/runs/run_Ibq6ozs8rdRqciEeN536AFZ4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_H7liwxlTJQFhzFcbfEzAsJU3/runs/run_Ibq6ozs8rdRqciEeN536AFZ4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_H7liwxlTJQFhzFcbfEzAsJU3/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:07:45.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:07:45] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:07:45] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:14:15.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_FBvuepdZTC2iULdn6x93xcxA\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_FBvuepdZTC2iULdn6x93xcxA/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:14:15.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_FBvuepdZTC2iULdn6x93xcxA/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:14:16.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_WEkFeIffrzAUlj9DbJb0WPNx\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_FBvuepdZTC2iULdn6x93xcxA/runs/run_WEkFeIffrzAUlj9DbJb0WPNx \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_FBvuepdZTC2iULdn6x93xcxA/runs/run_WEkFeIffrzAUlj9DbJb0WPNx \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_FBvuepdZTC2iULdn6x93xcxA/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:14:18.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:14:18] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:14:18] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:23:59.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_jZfHqFnSfKMlqCxIXoOFzpTM\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_jZfHqFnSfKMlqCxIXoOFzpTM/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:23:59.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_jZfHqFnSfKMlqCxIXoOFzpTM/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:24:05.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_fxvoQ7trowlsQ8Bah6HhhfdV\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_jZfHqFnSfKMlqCxIXoOFzpTM/runs/run_fxvoQ7trowlsQ8Bah6HhhfdV \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_jZfHqFnSfKMlqCxIXoOFzpTM/runs/run_fxvoQ7trowlsQ8Bah6HhhfdV \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_jZfHqFnSfKMlqCxIXoOFzpTM/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:24:07.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:24:07] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:24:07] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:33:12.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_VeEW1Xn9KDIGe9ij1E3JC2AQ\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_VeEW1Xn9KDIGe9ij1E3JC2AQ/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:33:13.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_VeEW1Xn9KDIGe9ij1E3JC2AQ/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:33:14.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_H63be4pNtlilhSn8FaB2uJ45\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_VeEW1Xn9KDIGe9ij1E3JC2AQ/runs/run_H63be4pNtlilhSn8FaB2uJ45 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_VeEW1Xn9KDIGe9ij1E3JC2AQ/runs/run_H63be4pNtlilhSn8FaB2uJ45 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_VeEW1Xn9KDIGe9ij1E3JC2AQ/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:33:16.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:33:16] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:33:16] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:34:48.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_5z1e3Ykt1gsZ9NP2CundbbAU\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_5z1e3Ykt1gsZ9NP2CundbbAU/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:34:48.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_5z1e3Ykt1gsZ9NP2CundbbAU/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:34:49.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_Ap4qsGrKijzgnkkA3JPy2QJ7\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_5z1e3Ykt1gsZ9NP2CundbbAU/runs/run_Ap4qsGrKijzgnkkA3JPy2QJ7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_5z1e3Ykt1gsZ9NP2CundbbAU/runs/run_Ap4qsGrKijzgnkkA3JPy2QJ7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_5z1e3Ykt1gsZ9NP2CundbbAU/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:34:51.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:34:51] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:34:51] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:35:50.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_QnDKa9eiMYQRVM38pFkXLXkf\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_QnDKa9eiMYQRVM38pFkXLXkf/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:35:51.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_QnDKa9eiMYQRVM38pFkXLXkf/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:35:52.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_ooyxRtbCQS7nWh9uWWPw6gL0\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_QnDKa9eiMYQRVM38pFkXLXkf/runs/run_ooyxRtbCQS7nWh9uWWPw6gL0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_QnDKa9eiMYQRVM38pFkXLXkf/runs/run_ooyxRtbCQS7nWh9uWWPw6gL0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_QnDKa9eiMYQRVM38pFkXLXkf/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:35:54.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:35:54] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:35:54] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:36:55.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_yaHXPt7XOXM7SRvQVAcQFe9C\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_yaHXPt7XOXM7SRvQVAcQFe9C/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:36:56.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_yaHXPt7XOXM7SRvQVAcQFe9C/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:36:57.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_Ja36qaJvPEVisOj1sqvykkbv\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_yaHXPt7XOXM7SRvQVAcQFe9C/runs/run_Ja36qaJvPEVisOj1sqvykkbv \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_yaHXPt7XOXM7SRvQVAcQFe9C/runs/run_Ja36qaJvPEVisOj1sqvykkbv \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_yaHXPt7XOXM7SRvQVAcQFe9C/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:36:59.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:36:59] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:36:59] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:38:48.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_3EvsCUfvmzspxOlM9kBVyNuX\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_3EvsCUfvmzspxOlM9kBVyNuX/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:38:49.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_3EvsCUfvmzspxOlM9kBVyNuX/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:38:50.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_WmuHJVXKF2pz79UO3JaF10Uw\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_3EvsCUfvmzspxOlM9kBVyNuX/runs/run_WmuHJVXKF2pz79UO3JaF10Uw \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_3EvsCUfvmzspxOlM9kBVyNuX/runs/run_WmuHJVXKF2pz79UO3JaF10Uw \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_3EvsCUfvmzspxOlM9kBVyNuX/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:38:52.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:38:52] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:38:52] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:42:49.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_uNBlteW9pNFzy1iHCIAsuEg6\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_uNBlteW9pNFzy1iHCIAsuEg6/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:42:49.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_uNBlteW9pNFzy1iHCIAsuEg6/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:42:52.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_WtEkmlOcwgJCfdDYITGCZdTX\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_uNBlteW9pNFzy1iHCIAsuEg6/runs/run_WtEkmlOcwgJCfdDYITGCZdTX \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_uNBlteW9pNFzy1iHCIAsuEg6/runs/run_WtEkmlOcwgJCfdDYITGCZdTX \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_uNBlteW9pNFzy1iHCIAsuEg6/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:42:54.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:42:54] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:42:54] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:45:12.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m✅ Created thread: thread_Wcs7JfOVZorRuPGmFhKRNoXh\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_Wcs7JfOVZorRuPGmFhKRNoXh/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:45:13.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m✅ Sent message to thread\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_Wcs7JfOVZorRuPGmFhKRNoXh/runs \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:45:14.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1m✅ Started run: run_Q70gWMXy83ZjRz04hxzGD92D\u001b[0m\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_Wcs7JfOVZorRuPGmFhKRNoXh/runs/run_Q70gWMXy83ZjRz04hxzGD92D \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_Wcs7JfOVZorRuPGmFhKRNoXh/runs/run_Q70gWMXy83ZjRz04hxzGD92D \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_Wcs7JfOVZorRuPGmFhKRNoXh/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-02-09 09:45:16.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_invoice\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1m✅ Received validation response\u001b[0m\n",
      "127.0.0.1 - - [09/Feb/2025 09:45:16] \"POST /check-expense HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [09/Feb/2025 09:45:16] \"POST /check-expense HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pickle\n",
    "import openai\n",
    "from threading import Thread\n",
    "from loguru import logger\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "API_KEY = \"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\"\n",
    "ASSISTANT_ID = \"asst_EpFa1gBPouBslsTcGOsLBEGE\"\n",
    "client = openai.OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Define allowed budgets and categories\n",
    "ALLOWED_BUDGETS = {\"Travel\": 10000, \"Meals\": 3000, \"Supplies\": 5000}\n",
    "ALLOWED_CATEGORIES = [\"Travel\", \"Meals\", \"Supplies\", \"Office Supplies\", \"Technology\", \"Training\", \"Entertainment\"]\n",
    "\n",
    "MODEL_FILE = \"expense_model.pkl\"\n",
    "DATA_FILE = \"synthetic_expense_data.csv\"\n",
    "\n",
    "class ExpenseModel:\n",
    "    def __init__(self):\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        generator = SyntheticDataGenerator()\n",
    "        self.df = generator.generate_data(n_samples=1000)\n",
    "        self.df.to_csv(DATA_FILE, index=False)\n",
    "        with open(MODEL_FILE, 'wb') as f:\n",
    "            pickle.dump(self.df, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            self.df = pickle.load(f)\n",
    "    def check_violation(self, expense):\n",
    "           category = expense.get(\"category\")\n",
    "           amount = expense.get(\"amount\", 0)\n",
    "           description = expense.get(\"description\", \"\").strip()\n",
    "    \n",
    "           violations = []\n",
    "           if category in ALLOWED_BUDGETS and float(amount) > float(ALLOWED_BUDGETS[category]):\n",
    "                  violations.append(f\"Over Budget: {amount} INR exceeds allowed budget of {ALLOWED_BUDGETS[category]} INR.\")\n",
    "           if category not in ALLOWED_CATEGORIES:\n",
    "                   violations.append(f\"Unauthorized Category: {category} is not allowed.\")\n",
    "           if category in ALLOWED_BUDGETS and float(amount) > float(ALLOWED_BUDGETS[category]) and description.lower() == \"no description\":\n",
    "                 violations.append(\"Missing Justification: High amount claimed but justification is missing.\")\n",
    "\n",
    "    # Create the validation result\n",
    "           violation_data = {\n",
    "                    \"expense_id\": expense.get(\"expense_id\", \"N/A\"),\n",
    "                   \"employee_id\": expense.get(\"employee_id\", \"N/A\"),\n",
    "                    \"category\": category,\n",
    "                     \"amount\": amount,\n",
    "                    \"violations\": violations if violations else \"No Violations\",\n",
    "                        }\n",
    "\n",
    "    # Append the validation data to the original expense dictionary\n",
    "           expense.update(violation_data)  # This ensures it is added to the same dictionary\n",
    "\n",
    "           return expense  # You can still return it for debugging or logging purposes\n",
    "\n",
    "\n",
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.categories = list(ALLOWED_BUDGETS.keys())\n",
    "        self.currencies = ['INR']\n",
    "        self.payment_methods = ['Credit Card', 'Cash', 'Net Banking', 'UPI']\n",
    "    \n",
    "    def generate_data(self, n_samples=1000, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        data = {\n",
    "            'expense_id': np.arange(1, n_samples + 1),\n",
    "            'employee_id': np.random.randint(1000, 2000, n_samples),\n",
    "            'amount': np.random.uniform(100, 10000, n_samples).round(2),\n",
    "            'category': np.random.choice(self.categories, n_samples),\n",
    "            'currency': np.random.choice(self.currencies, n_samples),\n",
    "            'vendor_country': np.random.choice(['IN', 'US', 'UK'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "            'payment_method': np.random.choice(self.payment_methods, n_samples),\n",
    "            'expense_date': [(datetime.today() - timedelta(days=np.random.randint(1, 30))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'submission_date': [(datetime.today() - timedelta(days=np.random.randint(0, 10))).strftime('%Y-%m-%d') for _ in range(n_samples)],\n",
    "            'description': np.random.choice(['Justified', 'no description'], n_samples, p=[0.7, 0.3]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = df.apply(self.rule_based_violation_check, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def rule_based_violation_check(self, row):\n",
    "        cat = row['category']\n",
    "        amt = row['amount']\n",
    "        description = row['description'].strip()\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) * 1.5:\n",
    "            return 1\n",
    "        if cat not in ALLOWED_CATEGORIES:\n",
    "            return 1\n",
    "        if amt > ALLOWED_BUDGETS.get(cat, 0) and description.lower() == \"no description\":\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "expense_model = ExpenseModel()\n",
    "\n",
    "\n",
    "\n",
    "def validate_invoice(json_data):\n",
    "    try:\n",
    "        # Input validation\n",
    "        if not json_data:\n",
    "            logger.error(\"❌ No invoice data provided\")\n",
    "            return None, \"No invoice data provided\"\n",
    "\n",
    "        # Create a new thread with the OpenAI Assistant\n",
    "        try:\n",
    "            thread = client.beta.threads.create()\n",
    "            logger.info(f\"✅ Created thread: {thread.id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to create thread: {str(e)}\")\n",
    "            return None, \"Failed to create OpenAI thread\"\n",
    "\n",
    "        # Send the invoice data to the assistant\n",
    "        try:\n",
    "            message = client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=str(json_data)  # Convert to string to ensure safe transmission\n",
    "            )\n",
    "            logger.info(\"✅ Sent message to thread\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to send message: {str(e)}\")\n",
    "            return None, \"Failed to send message to OpenAI\"\n",
    "\n",
    "        # Run the assistant on this thread\n",
    "        try:\n",
    "            run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=ASSISTANT_ID\n",
    "            )\n",
    "            logger.info(f\"✅ Started run: {run.id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to start run: {str(e)}\")\n",
    "            return None, \"Failed to start OpenAI assistant\"\n",
    "\n",
    "        # Wait for the assistant to process the request with timeout\n",
    "        max_retries = 30  # 30 seconds timeout\n",
    "        retry_count = 0\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                run_status = client.beta.threads.runs.retrieve(\n",
    "                    thread_id=thread.id,\n",
    "                    run_id=run.id\n",
    "                )\n",
    "                if run_status.status == \"completed\":\n",
    "                    break\n",
    "                elif run_status.status == \"failed\":\n",
    "                    logger.error(\"❌ Assistant run failed\")\n",
    "                    return None, \"OpenAI assistant run failed\"\n",
    "                elif run_status.status == \"expired\":\n",
    "                    logger.error(\"❌ Assistant run expired\")\n",
    "                    return None, \"OpenAI assistant run expired\"\n",
    "                \n",
    "                retry_count += 1\n",
    "                time.sleep(1)  # Wait 1 second before checking again\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"❌ Failed to check run status: {str(e)}\")\n",
    "                return None, \"Failed to check OpenAI assistant status\"\n",
    "\n",
    "        if retry_count >= max_retries:\n",
    "            logger.error(\"❌ Assistant run timed out\")\n",
    "            return None, \"OpenAI assistant timed out\"\n",
    "\n",
    "        # Retrieve the final message\n",
    "        try:\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            if not messages.data:\n",
    "                logger.error(\"❌ No response from assistant\")\n",
    "                return None, \"No response from OpenAI assistant\"\n",
    "                \n",
    "            reply = messages.data[0].content[0].text.value\n",
    "            logger.info(\"✅ Received validation response\")\n",
    "            \n",
    "            # Update the original data with validation result\n",
    "            json_data[\"validation_result\"] = reply\n",
    "            \n",
    "            return json_data, None  # Return (data, error)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to retrieve assistant response: {str(e)}\")\n",
    "            return None, \"Failed to get OpenAI assistant response\"\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Unexpected error in validate_invoice: {str(e)}\")\n",
    "        return None, f\"Unexpected error: {str(e)}\"\n",
    "\n",
    "\n",
    "@app.route('/generate-data', methods=['GET'])\n",
    "def generate_data():\n",
    "    return send_file(DATA_FILE, as_attachment=True)\n",
    "\n",
    "@app.route('/check-expense', methods=['POST'])\n",
    "def check_expense():\n",
    "    try:\n",
    "        data = request.json\n",
    "        if not data:\n",
    "            return jsonify({\"error\": \"No data provided\"}), 400\n",
    "\n",
    "        # Check violations\n",
    "        model_data = expense_model.check_violation(data)\n",
    "        if not model_data:\n",
    "            return jsonify({\"error\": \"Violation check failed\"}), 400\n",
    "\n",
    "        # Validate invoice\n",
    "        validated_data, error = validate_invoice(model_data)\n",
    "        if error:\n",
    "            return jsonify({\"error\": error}), 400\n",
    "\n",
    "        if not validated_data:\n",
    "            return jsonify({\"error\": \"Validation failed\"}), 400\n",
    "\n",
    "        # Return successful response\n",
    "        return jsonify(validated_data), 200\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error in check_expense: {str(e)}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=4000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "065d5d22-3df5-4179-9e55-fc4227f50cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loguru\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from loguru) (0.4.6)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru)\n",
      "  Downloading win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.6/61.6 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading win32_setctime-1.2.0-py3-none-any.whl (4.1 kB)\n",
      "Installing collected packages: win32-setctime, loguru\n",
      "Successfully installed loguru-0.7.3 win32-setctime-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73a479-078e-4c10-b923-ad920a95dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import openai\n",
    "import os\n",
    "from threading import Thread\n",
    "\n",
    "# Flask app initialization\n",
    "app = Flask(__name__)\n",
    "\n",
    "# OpenAI API Setup (Hardcoded API Key and Assistant ID)\n",
    "API_KEY = \"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\"\n",
    "ASSISTANT_ID = \"asst_EpFa1gBPouBslsTcGOsLBEGE\"\n",
    "\n",
    "client = openai.OpenAI(api_key=API_KEY)\n",
    "\n",
    "@app.route('/validate_invoice', methods=['POST'])\n",
    "def validate_invoice():\n",
    "    try:\n",
    "        # Get JSON data from request\n",
    "        invoice_data = request.json\n",
    "\n",
    "        if not invoice_data:\n",
    "            return jsonify({\"error\": \"No invoice data provided\"}), 400\n",
    "\n",
    "        # Create a new thread with the OpenAI Assistant\n",
    "        thread = client.beta.threads.create()\n",
    "        \n",
    "        # Send the invoice data to the assistant\n",
    "        client.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=f\"{invoice_data}\"  # Sending raw JSON invoice data\n",
    "        )\n",
    "\n",
    "        # Run the assistant on this thread\n",
    "        run = client.beta.threads.runs.create(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=ASSISTANT_ID\n",
    "        )\n",
    "\n",
    "        # Wait for the assistant to process the request\n",
    "        while True:\n",
    "            run_status = client.beta.threads.runs.retrieve(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "            if run_status.status == \"completed\":\n",
    "                break\n",
    "\n",
    "        # Retrieve the final message from the assistant\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        reply = messages.data[0].content[0].text.value  # Extract response\n",
    "\n",
    "        return jsonify({\"validation_result\": reply})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# Function to run Flask without conflicts in Jupyter Notebook\n",
    "def run_flask():\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=False)\n",
    "\n",
    "# Run Flask in a separate thread (so Jupyter doesn't crash)\n",
    "flask_thread = Thread(target=run_flask)\n",
    "flask_thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
